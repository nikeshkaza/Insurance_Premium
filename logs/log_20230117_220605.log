[2023-01-17 22:06:08,594] 	INFO 	30 	training.py 	get_pipeline_config() 	Pipeline configuration: PipelineConfig(pipeline_name='insurance-premium', artifact_dir='/Users/nikeshkaza/data_science/POC/insurance_premium/insurance_artifact')
[2023-01-17 22:06:08,594] 	INFO 	67 	training.py 	get_data_ingestion_config() 	Data ingestion config: DataIngestionConfig(data_ingestion_dir='/Users/nikeshkaza/data_science/POC/insurance_premium/insurance_artifact/data_ingestion/20230117_220605', download_dir='/Users/nikeshkaza/data_science/POC/insurance_premium/insurance_artifact/data_ingestion/20230117_220605/downloaded_files', file_name='insurance_premium', feature_store_dir='/Users/nikeshkaza/data_science/POC/insurance_premium/insurance_artifact/data_ingestion/20230117_220605/feature_store', failed_dir='/Users/nikeshkaza/data_science/POC/insurance_premium/insurance_artifact/data_ingestion/20230117_220605/failed_downloaded_files', datasource_url='mongodb+srv://nikeshkaza:OWUCXgQaZkCnE4ht@cluster0.fckbdxk.mongodb.net/?retryWrites=true&w=majority')
[2023-01-17 22:06:08,594] 	INFO 	39 	data_ingestion.py 	__init__() 	>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Starting data ingestion.<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
[2023-01-17 22:06:08,594] 	INFO 	110 	data_ingestion.py 	initiate_data_ingestion() 	Started downloading json file
[2023-01-17 22:06:08,594] 	INFO 	53 	data_ingestion.py 	export_data_into_feature_store() 	Exporting data from mongodb to feature store
[2023-01-17 22:06:09,487] 	INFO 	116 	data_ingestion.py 	initiate_data_ingestion() 	Converting and combining downloaded json into parquet file
[2023-01-17 22:06:09,490] 	INFO 	89 	data_ingestion.py 	convert_files_to_parquet() 	Parquet file will be created at: /Users/nikeshkaza/data_science/POC/insurance_premium/insurance_artifact/data_ingestion/20230117_220605/feature_store/insurance_premium
[2023-01-17 22:06:12,310] 	INFO 	128 	data_ingestion.py 	initiate_data_ingestion() 	Data ingestion artifact: DataIngestionArtifact(feature_store_file_path='/Users/nikeshkaza/data_science/POC/insurance_premium/insurance_artifact/data_ingestion/20230117_220605/feature_store/insurance_premium', download_dir='/Users/nikeshkaza/data_science/POC/insurance_premium/insurance_artifact/data_ingestion/20230117_220605/downloaded_files')
[2023-01-17 22:06:12,310] 	INFO 	87 	training.py 	get_data_validation_config() 	Data preprocessing config: DataValidationConfig(accepted_data_dir='/Users/nikeshkaza/data_science/POC/insurance_premium/insurance_artifact/data_validation/20230117_220605/accepted_data', rejected_data_dir='/Users/nikeshkaza/data_science/POC/insurance_premium/insurance_artifact/data_validation/20230117_220605/rejected_data', file_name='insurance_premium')
[2023-01-17 22:06:12,310] 	INFO 	151 	data_validation.py 	initiate_data_validation() 	Initiating data validation
[2023-01-17 22:06:12,407] 	INFO 	51 	data_validation.py 	read_data() 	Data frame is created using file: /Users/nikeshkaza/data_science/POC/insurance_premium/insurance_artifact/data_ingestion/20230117_220605/feature_store/insurance_premium
[2023-01-17 22:06:12,526] 	INFO 	52 	data_validation.py 	read_data() 	Number of row: 1338 and column: 7
[2023-01-17 22:06:12,526] 	INFO 	62 	data_validation.py 	get_missing_report() 	Preparing missing reports for each column
[2023-01-17 22:06:13,190] 	INFO 	72 	data_validation.py 	get_missing_report() 	Missing report prepared: {'age': MissingReport(total_row=1338, missing_row=0, missing_percentage=0.0), 'sex': MissingReport(total_row=1338, missing_row=0, missing_percentage=0.0), 'bmi': MissingReport(total_row=1338, missing_row=0, missing_percentage=0.0), 'children': MissingReport(total_row=1338, missing_row=0, missing_percentage=0.0), 'smoker': MissingReport(total_row=1338, missing_row=0, missing_percentage=0.0), 'region': MissingReport(total_row=1338, missing_row=0, missing_percentage=0.0), 'expenses': MissingReport(total_row=1338, missing_row=0, missing_percentage=0.0)}
[2023-01-17 22:06:13,190] 	INFO 	161 	data_validation.py 	initiate_data_validation() 	Saving preprocessed data.
[2023-01-17 22:06:13,434] 	INFO 	174 	data_validation.py 	initiate_data_validation() 	Data validation artifact: [DataValidationArtifact(accepted_file_path='/Users/nikeshkaza/data_science/POC/insurance_premium/insurance_artifact/data_validation/20230117_220605/accepted_data/insurance_premium', rejected_dir='/Users/nikeshkaza/data_science/POC/insurance_premium/insurance_artifact/data_validation/20230117_220605/rejected_data')]
[2023-01-17 22:06:13,434] 	INFO 	116 	training.py 	get_data_transformation_config() 	Data transformation config: DataTransformationConfig(file_name='insurance_premium', export_pipeline_dir='/Users/nikeshkaza/data_science/POC/insurance_premium/insurance_artifact/data_transformation/20230117_220605/transformed_pipeline', transformed_train_dir='/Users/nikeshkaza/data_science/POC/insurance_premium/insurance_artifact/data_transformation/20230117_220605/train', transformed_test_dir='/Users/nikeshkaza/data_science/POC/insurance_premium/insurance_artifact/data_transformation/20230117_220605/test', test_size=0.2)
[2023-01-17 22:06:13,434] 	INFO 	97 	data_transformation.py 	initiate_data_transformation() 	>>>>>>>>>>>Started data transformation <<<<<<<<<<<<<<<
[2023-01-17 22:06:13,701] 	INFO 	100 	data_transformation.py 	initiate_data_transformation() 	Number of row: [1338] and column: [7]
[2023-01-17 22:06:13,702] 	INFO 	103 	data_transformation.py 	initiate_data_transformation() 	Splitting dataset into train and test set using ration: 0.8:0.2
[2023-01-17 22:06:13,859] 	INFO 	105 	data_transformation.py 	initiate_data_transformation() 	Train dataset has number of row: [1072] and column: [7]
[2023-01-17 22:06:13,944] 	INFO 	108 	data_transformation.py 	initiate_data_transformation() 	Train dataset has number of row: [1072] and column: [7]
[2023-01-17 22:06:13,973] 	INFO 	88 	data_transformation.py 	get_data_transformation_pipeline() 	Data transformation pipeline: [Pipeline_8657a4d0c80a]
[2023-01-17 22:06:15,031] 	INFO 	141 	data_transformation.py 	initiate_data_transformation() 	Saving transformation pipeline at: [/Users/nikeshkaza/data_science/POC/insurance_premium/insurance_artifact/data_transformation/20230117_220605/transformed_pipeline]
[2023-01-17 22:06:15,944] 	INFO 	143 	data_transformation.py 	initiate_data_transformation() 	Saving transformed train data at: [/Users/nikeshkaza/data_science/POC/insurance_premium/insurance_artifact/data_transformation/20230117_220605/train/insurance_premium]
[2023-01-17 22:06:16,210] 	INFO 	147 	data_transformation.py 	initiate_data_transformation() 	Saving transformed test data at: [/Users/nikeshkaza/data_science/POC/insurance_premium/insurance_artifact/data_transformation/20230117_220605/test/insurance_premium]
[2023-01-17 22:06:16,452] 	INFO 	158 	data_transformation.py 	initiate_data_transformation() 	Data transformation artifact: [DataTransformationArtifact(transformed_train_file_path='/Users/nikeshkaza/data_science/POC/insurance_premium/insurance_artifact/data_transformation/20230117_220605/train/insurance_premium', exported_pipeline_file_path='/Users/nikeshkaza/data_science/POC/insurance_premium/insurance_artifact/data_transformation/20230117_220605/transformed_pipeline', transformed_test_file_path='/Users/nikeshkaza/data_science/POC/insurance_premium/insurance_artifact/data_transformation/20230117_220605/test/insurance_premium')]
[2023-01-17 22:06:16,453] 	INFO 	134 	training.py 	get_model_trainer_config() 	Model trainer config: ModelTrainerConfig(base_accuracy=0.6, trained_model_file_path='/Users/nikeshkaza/data_science/POC/insurance_premium/insurance_artifact/model_trainer/20230117_220605/trained_model/insurance_premium', metric_list=['f1', 'weightedPrecision', 'weightedRecall', 'weightedTruePositiveRate', 'weightedFalsePositiveRate', 'weightedFMeasure', 'truePositiveRateByLabel', 'falsePositiveRateByLabel', 'precisionByLabel', 'recallByLabel', 'fMeasureByLabel'])
[2023-01-17 22:06:25,594] 	INFO 	64 	model_trainer.py 	get_model() 	Creating Random Forest Classifier class.
